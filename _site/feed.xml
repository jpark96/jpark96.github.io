<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2017-11-20T15:36:48-08:00</updated><id>http://localhost:4000/</id><title type="html">jpark96.github.io</title><subtitle>Berkeley Bear's Blog for Machine Learning, Photography, and Life</subtitle><entry><title type="html">Probabilistic Graphical Models (Part I)</title><link href="http://localhost:4000/Hello-World/" rel="alternate" type="text/html" title="Probabilistic Graphical Models (Part I)" /><published>2014-03-03T00:00:00-08:00</published><updated>2014-03-03T00:00:00-08:00</updated><id>http://localhost:4000/Hello-World</id><content type="html" xml:base="http://localhost:4000/Hello-World/">&lt;p&gt;It is difficult to model probability. Consider medical diagnosis. There are thousands of symptoms with millions of possible causes; any of these possible causes or combination of causes can be the source of the patient’s symptoms. In situations where there are many uncertain factors interacting with each other, graphical models help break down the representational mess of stochastic systems. Daphne Koller and Nir Friedman provide a powerful, formal framework for representating, inferring, and learning probabilistic graphical models through proofs, helpful intuitions, and plenty of examples and exercises for practice.&lt;/p&gt;

&lt;table class=&quot;image&quot;&gt;
&lt;caption align=&quot;bottom&quot;&gt;&lt;a href=&quot;https://www.amazon.com/Probabilistic-Graphical-Models-Principles-Computation/dp/0262013193/ref=sr_1_1?ie=UTF8&amp;amp;qid=1511220417&amp;amp;sr=8-1&amp;amp;keywords=probabilistic+graphical+models&quot;&gt;Probabilistic Graphical Models&lt;/a&gt;&lt;/caption&gt;
&lt;tr&gt;&lt;td&gt;&lt;img src=&quot;../images/PGM_cover.jpg&quot; /&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;I personally recommend this book for anyone with interest in machine learning. The book makes you think critically about the capacity and expressive power of different variants of graphical models. It is an introductory graduate level textbook (I can only do around half the problems myself) and is a bit tedious with its insistance on proving the soundness and completeness of all properties. These notes are meant primarily for myself, but I thought it might help for anyone who is considering buying the book themselves or just want to taste test PGMs. Enjoy!&lt;/p&gt;

&lt;p&gt;Included:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Foundations&lt;/li&gt;
  &lt;li&gt;Bayesian Networks&lt;/li&gt;
  &lt;li&gt;Markov Networks&lt;/li&gt;
&lt;/ol&gt;
&lt;object data=&quot;../images/pgm_notes.pdf&quot; type=&quot;application/pdf&quot; width=&quot;700px&quot; height=&quot;700px&quot;&gt;
    &lt;embed src=&quot;../images/pgm_notes.pdf&quot; /&gt;
        This browser does not support PDFs. Please download the PDF to view it: &lt;a href=&quot;../images/pgm_notes.pdf&quot;&gt;Download PDF&lt;/a&gt;.&amp;lt;/p&amp;gt;
    &amp;lt;/embed&amp;gt;
&lt;/object&gt;</content><author><name></name></author><summary type="html">It is difficult to model probability. Consider medical diagnosis. There are thousands of symptoms with millions of possible causes; any of these possible causes or combination of causes can be the source of the patient’s symptoms. In situations where there are many uncertain factors interacting with each other, graphical models help break down the representational mess of stochastic systems. Daphne Koller and Nir Friedman provide a powerful, formal framework for representating, inferring, and learning probabilistic graphical models through proofs, helpful intuitions, and plenty of examples and exercises for practice.</summary></entry></feed>